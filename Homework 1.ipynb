{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c377860",
   "metadata": {},
   "source": [
    "## Homework 1 - Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa361016",
   "metadata": {},
   "source": [
    "### **Instructions**: The data file for this homework is LaptopSalesJanuary2008.csv, which can be downloaded from Blackboard.  Create a new jyputer notebook and save it as HW1AnsX_Y (where X is your team number and Y is your last name).  Where required, write your answers/paste screenshots into this Word document.  Your response should not exceed 100 words for each below question.  \n",
    "\n",
    "### Write every member’s full name and participation on the first cell of the notebook as follows. \n",
    "### Due Dates\n",
    "### - Indidivaul work - **Feb. 8, 2024**\n",
    "### - Group submission - **Feb. 10, 2024**\n",
    "|Participant |Posted Date |Completeness|Qualify     |Contribution%|Justification |\n",
    "|------------|------------|------------|------------|-------------|--------------|\n",
    "|Elikem      |02/08/2024--|90%---------|------------|-------------|--------------|\n",
    "|Trent       |02/08/2024--|80%---------|------------|-------------|--------------|\n",
    "|----------- |------------|------------|------------|-------------|--------------|\n",
    "|Michael     |02/08/2024--|90%---------|------------|-------------|--------------|\n",
    "|------------|------------|------------|------------|-------------|--------------|\n",
    "|Kayla       |02/08/2024--|80%---------|------------|-------------|--------------|\n",
    "|------------|------------|------------|------------|-------------|--------------|\n",
    "|Dashaun     |------------|%%%---------|------------|-------------|--------------|\n",
    "|------------|------------|------------|------------|-------------|--------------|\n",
    "|Scottie.    |02/08/2024--|80%---------|------------|-------------|--------------|\n",
    "|------------|------------|------------|------------|-------------|--------------|\t\n",
    "|----------- |------------|------------|------------|-------------|--------------|\t\n",
    "\n",
    "### Each member needs to submit the completed homework in the Python notebook and post it to the Group Discussion Forum by assigned date in order to receive credits.  \n",
    "### Each group only submits one Python notebook to the assignment link by the assigned date.  The notebook should have consent from the majority of the members.\n",
    "\n",
    "### The data set contains data for all sales of laptops at a computer chain in London in January 2008. This subset of the full dataset includes data for the entire year. \n",
    "\n",
    "### Methods for exploring data include looking at various data aggregations and summaries, both numerically and graphically.  This includes looking at each variable separately as well as looking at relationships between variables.  The purpose is to discover patterns and exceptions. For numerical variables, histograms and box plots can be used to learn about the distributions of their value, detect outliers, and find other information relevant to the analysis task.  Similarly, for categorical variables, we can use bar charts.  Scatter plots of pairs of numerical variables can be used to learn about possible relationships and the type of relationship and to detect outliers.  Also, to scatter matrix plots, we can use correlation tables to identify the possible relationship between the variables. \n",
    "\n",
    "## Tasks\n",
    "### Task A. Load the data and check if the data is loaded correctly by listing the number of records and attributes and displaying some records. Next, check the structure and information of the dataset, including the index, dtypes, columns, nonnull value, and memory usage.  Which variables are numerical?  Which are binary? Which are ordinal? Which are nominal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "laptopSales_df = pd.read_csv('LaptopSalesJanuary2008.csv')\n",
    "\n",
    "laptopSales_df\n",
    "\n",
    "print(laptopSales_df.index)\n",
    "\n",
    "print(laptopSales_df.dtypes)\n",
    "\n",
    "print(laptopSales_df.columns)\n",
    "\n",
    "## checking not null and memory usage \n",
    "\n",
    "laptopSales_df.notnull\n",
    "\n",
    "laptopSales_df.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d466d",
   "metadata": {},
   "source": [
    "### Task B. Change the variable names to be more suitable for analysis by following programming naming conventions, such as snake_case, camelCase, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltops_df.colums = [s.strip().replace('','_') for s in ltops_df.columns]\n",
    "ltops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d971a2d",
   "metadata": {},
   "source": [
    "### Task C.  To get a quick understanding of the distribution of the data.  Plot a histogram for each of the quantitative variables.  Based on the histogram and summary statistics, answer the following questions:\n",
    "#### a)\tWhich variable has the largest variability?\n",
    "      - Configuration\n",
    "#### b)\tWhich variables seem skewed?\n",
    "      - Configuration, Retail_Price, OS_X_Customer, OS_Y_Customer, OS_X_Store, OS_Y_Store, CustomerStoreDistance\n",
    "#### c)\tAre there any values that seem extreme (outliers)?\n",
    "     - OS_X_Store and OS_Y_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative_vars = ['retail_price', 'screen_size_(inches)', 'battery_life_(hours)', 'ram_(gb)', 'processor_speeds_(ghz)', 'hd_size_(gb)', 'customerstoredistance']\n",
    "\n",
    "for var in quantitative_vars:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(data=laptops_df, x=var, bins=20, kde=True)\n",
    "    plt.title(f'Histogram of {var}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3477b",
   "metadata": {},
   "source": [
    "### Task D. Compute the correlation table for the quantitative variable and generate a scatter plot matrix for these variables.\n",
    "- #### Which pair of variables are most strongly correlated?\n",
    "- #### How can we reduce the number of variables based on these correlations?\n",
    "- #### How would the correlations change if we normalized the data first?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "nunerical_variables = laptopSalesJan. select_dtypes(includes =['int64', 'float64']).colunns.tolist()\n",
    "lsjv2 = laptopSalesJan.drepna()\n",
    "\n",
    "print(lsjv2[nunerical_variables].corr)\n",
    "\n",
    "plt.figuro(figgizes(12, 20))\n",
    "\n",
    "for i, v1 in enunerate(numerical_variables):\n",
    "    for j, v2 in emumerate(numerical_variables) :\n",
    "        if i < j :\n",
    "            pit. subplot(len(nunerical_variables) // 2, 2, j + 1 )\n",
    "            seaborn.scatterplot(x=v1, y=v2, data=lsjv2 )\n",
    "            plt.title(f'(v1) vs (v2)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842ed75",
   "metadata": {},
   "source": [
    "### Task E.  Explore the relationship between the numerical variables by using a scatter plot matrix.  What does this plot show us? Present your insights within 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i split into 4 bc it was driving me crazy idk what i am doing\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV file and clean column names\n",
    "data_df = pd.read_csv('LaptopSalesJanuary2008.csv')\n",
    "data_df.columns = [s.strip().replace(' ', '_') for s in data_df.columns]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_columns = data_df.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Split numerical columns into four parts\n",
    "split_index = len(numerical_columns) // 4\n",
    "numerical_columns_parts = [numerical_columns[i:i+split_index] for i in range(0, len(numerical_columns), split_index)]\n",
    "\n",
    "# Plot scatter plot matrices for each part\n",
    "for i, part_columns in enumerate(numerical_columns_parts):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.pairplot(data_df[part_columns], plot_kws={'s': 20})  # Adjust the marker size here\n",
    "    plt.suptitle(f'Scatter Plot Matrix of Part {i+1} Numerical Values', y=1.02)\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "### In the dataset, various variables exhibit diverse levels of correlation and dispersion. Retail price demonstrates higher variability and dispersion compared to other attributes like screen size, battery life, and RAM, which appear more uniform and closely aligned. This disparity implies potential patterns and insights to explore, suggesting that retail price might be influenced by a broader range of factors compared to the more standardized attributes, offering avenues for further analysis and understanding of underlying trends within the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4acb6",
   "metadata": {},
   "source": [
    "### Task F. Create a bar chart, showing the average retail price by store. Which store has the highest average? Which has the lowest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Dataframe by 'Store_Postcode'\n",
    "laptopSales_df.sort_values([\"Store_Postcode\"], axis=0, ascending=[False], inplace=True)\n",
    "\n",
    "# Calculate the average by each 'Store Postcode'\n",
    "average = laptopSales_df.groupby(['Store_Postcode'])['Retail_Price'].mean()\n",
    "\n",
    "# Display average\n",
    "print(average)\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10,5))\n",
    "# Plot the average on bar graph\n",
    "average.plot(kind='bar', color='g', width=0.3)\n",
    "# Title\n",
    "plt.title(\"Average Retail Price By Store\")\n",
    "# x axis label\n",
    "plt.xlabel(\"Stores\")\n",
    "# y axis label\n",
    "plt.ylabel(\"Retail Price\")\n",
    "# x axis ticks rotated\n",
    "plt.xticks(rotation=45)\n",
    "# Adjust layout \n",
    "plt.tight_layout()\n",
    "\n",
    "# Display chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb9733",
   "metadata": {},
   "source": [
    "### Task G. To better compare retail prices across stores, create side-by-side boxplots of retail price by store. Now compare the prices in the two stores from (F). Does there seem to be a difference between their price distributions?\n",
    " - There is a $10-$15 difference between the price distribution of stores \"N17 6QA\" and \"W4 3PH\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30676b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting dataframe by \"Store_Postcode\"\n",
    "laptopSales_df.sort_values([\"Store_Postcode\"], axis=0, ascending=[False], inplace=True)\n",
    "#print(laptopSales_df)\n",
    "\n",
    "# Retail Price boxplot by all \"Store_Postcode\"\n",
    "ax = laptopSales_df.boxplot(column='Retail_Price', by='Store_Postcode', figsize=(20,6))\n",
    "\n",
    "# Creating a new datafrome with only \"Store_Postcode\" and \"Retail_Price\" columns\n",
    "sp_pr = laptopSales_df[['Store_Postcode', 'Retail_Price']].copy()\n",
    "\n",
    "# store_1 = only rows containing \"N17 6QA\"\n",
    "store_1 = sp_pr[sp_pr[\"Store_Postcode\"] == \"N17 6QA\"]\n",
    "# store_2 = only rows containing \"W4 3PH\"\n",
    "store_2 = sp_pr[sp_pr[\"Store_Postcode\"] == \"W4 3PH\"]\n",
    "\n",
    "# Placement for figures\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\n",
    "\n",
    "# Figure 1 => Retail_Price boxplot of store_1 grouped by \"N17 6QA\"\n",
    "ax = store_1.boxplot(column='Retail_Price', by='Store_Postcode', ax=axes[0])\n",
    "\n",
    "# Fig 1 title\n",
    "plt.title(\"Retail Price of N17 6QA\") \n",
    "\n",
    "# Figure 2 => Retail_Price boxplot of store_2 grouped by \"W4 3PH\"\n",
    "ax = store_2.boxplot(column='Retail_Price', by='Store_Postcode', ax=axes[1], grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e062ea",
   "metadata": {},
   "source": [
    "### Task H. Describe how you would handle records with outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Replacing extreme values with less extreme values .\n",
    "# 2. Removing data points that significantly deviate from the rest of the dataset.\n",
    "# 3. Applying mathematical transformations to the data to reduce the impact of outliers.\n",
    "# 4. Using methods less sensitive to outliers, regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
